{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#import wandb\n",
    "#from wandb.keras import WandbCallback\n",
    "\n",
    "from src.Configs.Config import config\n",
    "from DataPipeline import DataPipeline\n",
    "from DatasetDownloader import DatasetDownloader\n",
    "from Visualizer import Visualizer, GANMonitor\n",
    "from src.Models.CycleGAN import CycleGAN\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "adverserial_loss = tf.keras.losses.MeanAbsoluteError()\n",
    "def generator_fake_adverserial_loss(discriminator_fake_output):\n",
    "    fake_loss = adverserial_loss(tf.ones_like(discriminator_fake_output), discriminator_fake_output)\n",
    "    return fake_loss\n",
    "\n",
    "\n",
    "def discriminator_loss(real, fake):\n",
    "    real_loss = adverserial_loss(tf.ones_like(real), real)\n",
    "    fake_loss = adverserial_loss(tf.zeros_like(fake), fake)\n",
    "    return (real_loss + fake_loss) * 0.5\n",
    "\n",
    "#wandb.init(project='IANNwTF')\n",
    "#wandb.config = config\n",
    "from src.Models.PatchGAN import PatchGANDiscriminator, PatchGANGenerator\n",
    "\n",
    "logging.basicConfig(encoding='utf-8', level=logging.INFO)\n",
    "\n",
    "dataset_downloader = DatasetDownloader(url=\"https://people.eecs.berkeley.edu/~taesung_park/CycleGAN/datasets/ukiyoe2photo.zip\", output_filepath=\"Data/Downloads/ukiyoe-dataset.zip\")\n",
    "dataset_downloader.unpack(output_filepath=\"Data/\")\n",
    "\n",
    "\"\"\"datasetA = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Data/ukiyoe2photo/trainA\",\n",
    "    labels=None,\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None, subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False)\n",
    "\n",
    "datasetB = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"Data/ukiyoe2photo/trainB\",\n",
    "    labels=None,\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=None,\n",
    "    validation_split=None, subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False)\"\"\"\n",
    "\n",
    "datasetA = tf.data.Dataset.from_tensor_slices([tf.random.normal([256,256,3]) for i in range(100)])\n",
    "datasetB = tf.data.Dataset.from_tensor_slices([tf.random.normal([256,256,3]) for i in range(100)])\n",
    "\n",
    "\n",
    "dataPipeline = DataPipeline()\n",
    "\n",
    "trainA_dataset = dataPipeline.batch_preparation(datasetA)\n",
    "trainB_dataset = dataPipeline.batch_preparation(datasetB)\n",
    "\n",
    "#datasetA = dataPipeline.normalize_dataset(datasetA)\n",
    "#datasetB = dataPipeline.normalize_dataset(datasetB)\n",
    "\n",
    "#trainA_dataset, validationA_dataset, testA_dataset = dataPipeline.split_dataset(dataset=datasetA, test_ratio=0.2, validation_ratio=0.1)\n",
    "#trainB_dataset, validationB_dataset, testB_dataset = dataPipeline.split_dataset(dataset=datasetB, test_ratio=0.2, validation_ratio=0.1)\n",
    "\n",
    "\"\"\"visualizer = Visualizer()\n",
    "\n",
    "visualizer.show_dataset_images(trainA_dataset, 5)\n",
    "visualizer.show_dataset_images(trainB_dataset, 5)\n",
    "\n",
    "ganMonitor = GANMonitor(trainA_dataset)\"\"\"\n",
    "\n",
    "generator_AtoB = PatchGANGenerator()\n",
    "generator_BtoA = PatchGANGenerator()\n",
    "\n",
    "discriminator_A = PatchGANDiscriminator()\n",
    "discriminator_B = PatchGANDiscriminator()\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "\n",
    "model = CycleGAN(generator_AtoB, generator_BtoA, discriminator_A, discriminator_B)\n",
    "model.compileT(tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5), tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5), tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5), tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5), tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanAbsoluteError(), tf.keras.losses.MeanAbsoluteError(), generator_fake_adverserial_loss, discriminator_loss)\n",
    "\"\"\"model.fit(\n",
    "    tf.data.Dataset.zip((trainA_dataset, trainB_dataset)),\n",
    "    epochs=2)\"\"\"\n",
    "print(\"Ende\")\n",
    "\n",
    "#model = CycleGAN()\n",
    "for epoch in range(4):\n",
    "    epoch_loss_agg = []\n",
    "    for trainA_dataset in trainA_dataset:\n",
    "        losses = model.train_step(trainA_dataset, trainA_dataset)\n",
    "    print(losses)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}